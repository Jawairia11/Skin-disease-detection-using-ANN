{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7f6cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and prepare the MNIST dataset to be acceptable for the model\n",
    "(x_train , y_train),(x_test , y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1 , 784)) /255.0\n",
    "x_test = x_test.reshape((-1 ,784))/255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337951c5",
   "metadata": {},
   "source": [
    "When loading the MNIST dataset from Keras, it is common to divide the pixel values by 255.0. This step is performed as a form of data normalization or scaling.\n",
    "\n",
    "The pixel values in the MNIST dataset range from 0 to 255, representing different levels of grayscale intensity. Dividing the pixel values by 255.0 scales them down to a range of 0 to 1. This normalization process ensures that all pixel values are within a standardized range, which can benefit the training process of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "99aec0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784) (60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape , y_train.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbadfe16",
   "metadata": {},
   "source": [
    "### Train the model with batch size 8 and layers  3(128,64,32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5408430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple ANN architecture (input layer = 1 )\n",
    "\n",
    "cnnmodel = Sequential([\n",
    "    Dense(128, activation = 'relu' , input_shape=(784 , )),\n",
    "    Dense(64 , activation = 'relu'),\n",
    "    Dense(32, activation= 'softmax'),\n",
    "    Dense(10, activation= 'softmax') ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "## `ReLU (Rectified Linear Unit):`\n",
    "    \n",
    " ReLU is a popular activation function used in the hidden layers of deep neural networks. It computes the element-wise maximum of 0 and the input value. Mathematically, ReLU can be defined as f(x) = max(0, x). `ReLU introduces non-linearity into the network, enabling the model to learn complex relationships between features`. It helps alleviate the vanishing gradient problem and can lead to faster convergence during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "14089e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model \n",
    "cnnmodel.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "73fd2f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 21s 3ms/step - loss: 1.1966 - accuracy: 0.4804 - val_loss: 0.8012 - val_accuracy: 0.6064\n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 21s 3ms/step - loss: 0.4773 - accuracy: 0.8100 - val_loss: 0.2487 - val_accuracy: 0.9497\n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 21s 3ms/step - loss: 0.1620 - accuracy: 0.9635 - val_loss: 0.1249 - val_accuracy: 0.9695\n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 21s 3ms/step - loss: 0.1166 - accuracy: 0.9713 - val_loss: 0.1162 - val_accuracy: 0.9724\n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 21s 3ms/step - loss: 0.0939 - accuracy: 0.9771 - val_loss: 0.1126 - val_accuracy: 0.9728\n"
     ]
    }
   ],
   "source": [
    "# Train the model on batchsize 8\n",
    "S = time.time()\n",
    "cnnmodel.fit(x_train,y_train , epochs=5, batch_size=8 , validation_data=(x_test , y_test))\n",
    "#cnnmodel.fit(x_train,y_train ,epochs=5 ,  validation_data=(x_test , y_test))\n",
    "E = time.time()\n",
    "\n",
    "# if we donot mention batch size , by default it takes 32 batch size \n",
    "# There are 60,000 examples and if we mention batch size 64 , then dividing by examples by  64 , it will give 938 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "95f1e87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1126 - accuracy: 0.9728\n",
      "Test Accuracy : 0.9728000164031982\n",
      "Total time taken while training  104.1966233253479\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model \n",
    "test_loss , test_acc = cnnmodel.evaluate(x_test , y_test)\n",
    "\n",
    "# joblib.dump(cnnmodel, 'cnn_model'.joblib)\n",
    "\n",
    "print(f\"Test Accuracy : {test_acc}\") \n",
    "print(\"Total time taken while training \" , E-S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8788c",
   "metadata": {},
   "source": [
    "### Train the model on Batch size 16 , and hidden layers 3( 64 ,64 , 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "199e3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnmodel_16 = Sequential([\n",
    "    Dense(64, activation = 'relu' , input_shape=(784 , )),\n",
    "    Dense(64 , activation = 'relu'),\n",
    "    Dense(32, activation= 'softmax'),\n",
    "    Dense(10, activation= 'softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9c68d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model \n",
    "cnnmodel_16.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "51180830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 10s 2ms/step - loss: 0.9839 - accuracy: 0.7418 - val_loss: 0.5331 - val_accuracy: 0.7791\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.4677 - accuracy: 0.7963 - val_loss: 0.4202 - val_accuracy: 0.8651\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.3289 - accuracy: 0.9189 - val_loss: 0.2459 - val_accuracy: 0.9603\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.1926 - accuracy: 0.9662 - val_loss: 0.1797 - val_accuracy: 0.9672\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.1383 - accuracy: 0.9726 - val_loss: 0.1543 - val_accuracy: 0.9685\n"
     ]
    }
   ],
   "source": [
    "# Train the model on \n",
    "S = time.time()\n",
    "cnnmodel_16.fit(x_train,y_train , epochs=5, batch_size=16 , validation_data=(x_test , y_test))\n",
    "#cnnmodel.fit(x_train,y_train ,epochs=5 ,  validation_data=(x_test , y_test))\n",
    "E = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9c64c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1543 - accuracy: 0.9685\n",
      "Test Accuracy : 0.968500018119812\n",
      "Total time taken while training  45.207777976989746\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model \n",
    "test_loss_16 , test_acc_16 = cnnmodel_16.evaluate(x_test , y_test)\n",
    "\n",
    "# joblib.dump(cnnmodel, 'cnn_model'.joblib)\n",
    "\n",
    "print(f\"Test Accuracy : {test_acc_16}\") \n",
    "print(\"Total time taken while training \" , E-S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d5126",
   "metadata": {},
   "source": [
    "### Train the model on 32 batch size , 2 hidden layers (64 ,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "04d67741",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnmodel_32 = Sequential([\n",
    "    Dense(64, activation = 'relu' , input_shape=(784 , )),\n",
    "    Dense(32 , activation = 'relu'),\n",
    "    Dense(10, activation= 'softmax')\n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "93dd98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model \n",
    "cnnmodel_32.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "de50e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2839 - accuracy: 0.9175 - val_loss: 0.1549 - val_accuracy: 0.9524\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1370 - accuracy: 0.9594 - val_loss: 0.1379 - val_accuracy: 0.9573\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1005 - accuracy: 0.9692 - val_loss: 0.1038 - val_accuracy: 0.9686\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0781 - accuracy: 0.9754 - val_loss: 0.0999 - val_accuracy: 0.9712\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0644 - accuracy: 0.9799 - val_loss: 0.1014 - val_accuracy: 0.9678\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "S = time.time()\n",
    "cnnmodel_32.fit(x_train,y_train , epochs=5, batch_size=32 , validation_data=(x_test , y_test))\n",
    "#cnnmodel.fit(x_train,y_train ,epochs=5 ,  validation_data=(x_test , y_test))\n",
    "E = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6526ce1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1014 - accuracy: 0.9678\n",
      "Test Accuracy : 0.9678000211715698\n",
      "Total time taken while training  23.051255226135254\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model \n",
    "test_loss_32 , test_acc_32 = cnnmodel_32.evaluate(x_test , y_test)\n",
    "\n",
    "# joblib.dump(cnnmodel, 'cnn_model'.joblib)\n",
    "\n",
    "print(f\"Test Accuracy : {test_acc_32}\") \n",
    "print(\"Total time taken while training \" , E-S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf041db",
   "metadata": {},
   "source": [
    "### Train the model on 64 batch size and  2 hidden layers 2(128,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ad4e205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnmodel_64 = Sequential([\n",
    "    Dense(128, activation = 'relu' , input_shape=(784 , )),\n",
    "    Dense(64 , activation = 'relu'),\n",
    "    Dense(10, activation= 'softmax')\n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "69710792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model \n",
    "cnnmodel_64.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15207818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 4s 3ms/step - loss: 0.2734 - accuracy: 0.9221 - val_loss: 0.1269 - val_accuracy: 0.9626\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1122 - accuracy: 0.9664 - val_loss: 0.0919 - val_accuracy: 0.9716\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0784 - accuracy: 0.9764 - val_loss: 0.0796 - val_accuracy: 0.9757\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0582 - accuracy: 0.9821 - val_loss: 0.0766 - val_accuracy: 0.9754\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 0.0775 - val_accuracy: 0.9759\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "S = time.time()\n",
    "cnnmodel_64.fit(x_train,y_train , epochs=5, batch_size=64 , validation_data=(x_test , y_test))\n",
    "#cnnmodel.fit(x_train,y_train ,epochs=5 ,  validation_data=(x_test , y_test))\n",
    "E = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "331db2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9759\n",
      "Test Accuracy : 0.9758999943733215\n",
      "Total time taken while training  16.147433280944824\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model \n",
    "test_loss_64 , test_acc_64 = cnnmodel_64.evaluate(x_test , y_test)\n",
    "\n",
    "# joblib.dump(cnnmodel, 'cnn_model'.joblib)\n",
    "\n",
    "print(f\"Test Accuracy : {test_acc_64}\") \n",
    "print(\"Total time taken while training \" , E-S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7645073f",
   "metadata": {},
   "source": [
    "### Train the model on 128 batch size , 2 hidden layers (64 ,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "821b6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnmodel_128 = Sequential([\n",
    "    Dense(64, activation = 'relu' , input_shape=(784 , )),\n",
    "    Dense(32 , activation = 'relu'),\n",
    "    Dense(10, activation= 'softmax')\n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfa65357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model \n",
    "cnnmodel_128.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4d74219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.4296 - accuracy: 0.8770 - val_loss: 0.2235 - val_accuracy: 0.9348\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1890 - accuracy: 0.9463 - val_loss: 0.1549 - val_accuracy: 0.9534\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1398 - accuracy: 0.9585 - val_loss: 0.1316 - val_accuracy: 0.9598\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1124 - accuracy: 0.9669 - val_loss: 0.1114 - val_accuracy: 0.9655\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9723 - val_loss: 0.0984 - val_accuracy: 0.9702\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "S = time.time()\n",
    "cnnmodel_128.fit(x_train,y_train , epochs=5, batch_size=128 , validation_data=(x_test , y_test))\n",
    "#cnnmodel.fit(x_train,y_train ,epochs=5 ,  validation_data=(x_test , y_test))\n",
    "E = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6597a79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9759\n",
      "Test Accuracy : 0.9758999943733215\n",
      "Total time taken while training  8.488483667373657\n"
     ]
    }
   ],
   "source": [
    "test_loss_128 , test_acc_128 = cnnmodel_64.evaluate(x_test , y_test)\n",
    "\n",
    "# joblib.dump(cnnmodel, 'cnn_model'.joblib)\n",
    "\n",
    "print(f\"Test Accuracy : {test_acc_128}\") \n",
    "print(\"Total time taken while training \" , E-S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbda77",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7e2a72e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Batch_size = 8</td>\n",
       "      <td>0.9728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batch_size =16</td>\n",
       "      <td>0.9685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batch_size = 32</td>\n",
       "      <td>0.9678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Batch_size = 64</td>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Batch_size = 128</td>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Accuracy\n",
       "0     Batch_size = 8    0.9728\n",
       "1   Batch_size =16      0.9685\n",
       "2    Batch_size = 32    0.9678\n",
       "3   Batch_size = 64     0.9759\n",
       "4   Batch_size = 128    0.9759"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "'Model' : ['Batch_size = 8','Batch_size =16  ','Batch_size = 32','Batch_size = 64 ',' Batch_size = 128' ],\n",
    "'Accuracy': [ test_acc, test_acc_16 , test_acc_32, test_acc_64, test_acc_128 ] })\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2aa5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
